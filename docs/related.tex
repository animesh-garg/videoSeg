\section{Related Work}
The problem of foreground tracking and more generally, the problem of video segmentation are well studied in the field of Computer Vision. Many of the prominent approaches treat the problem of video segmentation as that of combining segments obtained independently for various frames. A standard approach is to leverage standard image segmentation algorithms like \cite{CPMC} and filter the segmentation candidates to ensure consistency accross frames. Another commonly used approach where the generated segmentations rely on temporal information is to incoorporate the optical flow information of the frame along with the intensity as an additional layer image and use segmentation algorithms for this layered image eg \cite{LeordeanuSS12}. We observe that these common methods either do not incoorporate temporal information to generate segmentations or only use local temporal signals (from the next frame). In this work we aim to experiment with formulations which jointly capture the temporal information for the whole video aand we therefore tackle the problem of video segmentation as a global optimization problem.
